{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_df = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    symbol,\n",
    "    date_format(open_timestamp, 'EEEE') as day_of_week,\n",
    "    date_format(open_timestamp, 'HH') as hour_of_day,\n",
    "    avg(number_of_trade) as avg_trades,\n",
    "    avg(volume) as avg_volume\n",
    "FROM spot_data\n",
    "GROUP BY \n",
    "    symbol, \n",
    "    date_format(open_timestamp, 'EEEE'),\n",
    "    date_format(open_timestamp, 'HH')\n",
    "ORDER BY avg_volume DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"Top 10 most active trading periods:\")\n",
    "activity_df.show(10)\n",
    "activity_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "daily_vol = spark.sql(\"\"\"\n",
    "WITH daily_prices AS (\n",
    "    SELECT \n",
    "        symbol,\n",
    "        date_format(open_timestamp, 'yyyy-MM-dd') as trade_date,\n",
    "        max(high_price) as daily_high,\n",
    "        min(low_price) as daily_low,\n",
    "        first(open_price) as daily_open,\n",
    "        last(close_price) as daily_close,\n",
    "        avg(close_price) as avg_price\n",
    "    FROM spot_data\n",
    "    GROUP BY symbol, date_format(open_timestamp, 'yyyy-MM-dd')\n",
    ")\n",
    "SELECT \n",
    "    symbol,\n",
    "    trade_date,\n",
    "    ((daily_high - daily_low) / avg_price) * 100 as price_range_volatility,\n",
    "    ((daily_high - daily_low) / daily_low) * 100 as hl_volatility,\n",
    "    abs((daily_close - daily_open) / daily_open) * 100 as oc_volatility\n",
    "FROM daily_prices\n",
    "ORDER BY trade_date\n",
    "\"\"\")\n",
    "\n",
    "print(\"Daily Volatility Analysis:\")\n",
    "daily_vol.show(10)\n",
    "daily_vol.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intraday_vol = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    symbol,\n",
    "    date_format(open_timestamp, 'yyyy-MM-dd') as trade_date,\n",
    "    date_format(open_timestamp, 'HH') as hour_of_day,\n",
    "    ((max(high_price) - min(low_price)) / avg(close_price)) * 100 as hourly_volatility,\n",
    "    avg(number_of_trade) as avg_trades,  -- Changed from number_of_trades to number_of_trade\n",
    "    avg(volume) as avg_volume\n",
    "FROM spot_data\n",
    "GROUP BY \n",
    "    symbol,\n",
    "    date_format(open_timestamp, 'yyyy-MM-dd'),\n",
    "    date_format(open_timestamp, 'HH')\n",
    "ORDER BY trade_date, hour_of_day\n",
    "\"\"\")\n",
    "\n",
    "print(\"Intraday Volatility Analysis:\")\n",
    "intraday_vol.show(10)\n",
    "intraday_vol.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
